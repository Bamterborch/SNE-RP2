\section{Research Question}

Nikhef deals with enormous amounts of data to transport and process, the amounts of data keep growing.  
Interfaces of 100GB/s are getting common for servers
With the growth of the amount of data, system specifications also need to grow.
Generating UDP traffic is easy, a lot of tools are able to generate high amounts of UDP traffic, since UDP does not keep track of sessions which doesn't impact memory usage on systems. The tools basically dump traffic onto the line to fill it up. When TCP sessions come into play.
The host, generating the data, has to appoint system resources for the sessions and has to keep track of them. The three way handshake as a start of the session also requires performance from the generating machine. This is how machines are brought down to their knees. A depletion of resources will break down every system. \\
  
\textbf{The research question is as follows:}\\
How to perform high bandwidth session based throughput tests? \\

The term "high bandwidth" references to 40Gb/s. \\
The term "session based" references to TCP traffic. \\

Depending on the requirements of the system a different test could be needed. 
So therefore this research will also focus on the specifics of data generation and what tool specifics are needed for a defined set of tests. This creates a framework for the needs of high bandwidth throughput testing.  

