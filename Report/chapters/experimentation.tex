\chapter{experiments}\label{ch:experiments}
All experiments described in this chapter are executed in a test environment at NIKHEF. The test environment is displayed in image \ref{fig:testenv}.

\todo[inline]{insert image of test environment}

Three identical servers (A, B and C)  are used to perform the tests. Table \ref{tab:testmachines} contains the specifics of the three servers. 
These servers are all connected to a Juniper QFX10k2 (device S). This switch has 32 40Gb/s QFSP ports. 
Some of these ports are configured as a 100Gb/s interface. 
During the experiments 2 extra machines are introduced into the network. Both containing 100Gb/s Mellanox cards.
Table \ref{tab:ppc-intel} contains the information about the extra machines.   

Device A is always the receiving end of the test. Depending on the tests the source can be machine B, C or B and C.
For possible +40Gb/s tests, one of the 100Gb/s machines (D or E) can be used.

Machine M is a Simple Network Management Protocol (SNMP) server. This SNMP server query's the machines every second for status. As seen in the image of the test environment \ref{fig:testenv}. SNMP is active on a different interface of the devices.  

\sebsection{Iperf3}
When Using Iperf3, packets can be generated with a simple one liner.
To make it to 40Gb/s, eight separate threads have to be started when MTU size is set to default.
When an MTU size of 9000 (jumbo packets) is used, 2 threads where needed to generate 40Gb/s. 
So this is useful inside company networks that are under control of the person using iPerf3. 

\todo[inline]{insert images of client, server and network load) 
\todo [inline] {insert image of test}

\subsection{Hping}

\todo[inline]{insert images of client, server and network load)
\subsection{Bonesi}

\todo[inline]{insert images of client, server and network load)
\subsection{DPDK}

\todo[inline]{insert images of client, server and network load)
